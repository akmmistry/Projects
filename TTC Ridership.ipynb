{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis Of TTC Ridership\n",
    "** Group H - Final Project**<br>\n",
    "** Data Source :** https://www.toronto.ca/city-government/data-research-maps/toronto-progress-portal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Used**<br>\n",
    "1. **sqlalchemy** package to save and read data from sqllite database\n",
    "2. **numpy**<br>round(), mean(), arange(), array(), matrix()<br><br>\n",
    "3. **panda**<br>concat(), read_sql_query(), read_excel(), read_csv(), autocorrelation_plot()\n",
    "   pandas.plotting.table() draw data table in graph<br><br>\n",
    "4. **dataframe**<br>set_index(), reset_index(), sort_index(), shift(), drop(), ffill(), fillna(0), astype(), to_sql(),\n",
    "   min(), max(), sum(), mean(), groupby(), head(), tail(), transpose()<br><br>\n",
    "5. **str**<br>format(), replace()<br><br>\n",
    "6. **pyplot**<br>plot(), subplots(), acorr(), scatter() savefig()<br><br>\n",
    "7. **sklearn**<br>LinearRegression(), fit(), score(), predict()<br><br>\n",
    "8. **statsmodels**<br>ARIMA() model, fit(), forecast(), mean_squared_error()<br><br>\n",
    "9. **language**<br>For loop, \n",
    "   immediate if conditions (True if len(df)>0 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and pandas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas.plotting import table\n",
    "from sqlalchemy import create_engine # database connection\n",
    "\n",
    "# Import visualization libraries and set %mathplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "dbName = 'sqlite:///TTCRidership.db'\n",
    "\n",
    "# Table Names\n",
    "tnPeakRiders = 'PeakRiders'\n",
    "tnNonPeakRiders = 'NonPeakRiders'\n",
    "tnRidershipAnalysis = 'RidershipAnalysis'\n",
    "tnMonthlyRiders = 'MonthlyRiders'\n",
    "tnRidershipRevenues = 'RidershipRevenues'\n",
    "\n",
    "# Column names to fix for peak/non-peak riders data\n",
    "colToFixRidesPeak = 'TTC Annual Passenger Rides Peak (000s)'\n",
    "colToFixRidesNonPeak = 'TTC Annual Passenger Rides Non-Peak (000s)'\n",
    "\n",
    "# New column names for peak/non-peak riders data\n",
    "newColRidesPeak = 'PeakRides'\n",
    "newColRidesNonPeak = 'NonPeakRides'\n",
    "\n",
    "# Column name for monthly riders data\n",
    "colMonthlyRidership = 'TTC Monthly Ridership'\n",
    "\n",
    "# Source file names\n",
    "srcFileRidesPeak = 'TTC Annual Passenger Rides Peak.csv'\n",
    "srcFileRidesNonPeak = 'TTC Annual Passenger Rides Non-Peak.csv'\n",
    "srcFileMonthlyRiders = 'TTC Monthly Ridership.csv'\n",
    "srcFileRidershipRevenues = 'TTC Ridership Revenues.csv'\n",
    "\n",
    "# Initializes database with filename TTCRidership.db in current directory\n",
    "ttcDbConn = create_engine(dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Database related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read data from sqllite table\n",
    "def ReadTableFromDB(tableName, dbConn):\n",
    "    # read from sqllite db\n",
    "    df = pd.read_sql_query(\"SELECT * FROM {tn};\".format(tn=tableName), dbConn)\n",
    "    \n",
    "    #set the index back to first column of the table,\n",
    "    df = df.set_index(df.columns[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to check if table exist in the sqllite database\n",
    "def IsTableExists(tableName, dbConn):\n",
    "    sql=\"SELECT name FROM sqlite_master WHERE type='table' AND name='{tn}';\".format(tn=tableName)\n",
    "    df = pd.read_sql_query(sql, dbConn)\n",
    "    exists = True if len(df)>0 else False\n",
    "    return exists\n",
    "\n",
    "# Function to write data frame in the sqllite database\n",
    "def SaveDataframeInDB(dataFrame, tableName, dbConn):\n",
    "    if dbConn is None:\n",
    "        print('The dbConn is required to update database')\n",
    "    else:\n",
    "        dataFrame.to_sql(tableName, dbConn, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reading and cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix the accumulated revenue values \n",
    "def FixAccumulatedMonthValues(data):\n",
    "    previousColumn = ''\n",
    "    for column in data.columns[:0:-1]:\n",
    "        if (previousColumn==''):\n",
    "            previousColumn = column\n",
    "\n",
    "        if (previousColumn != column):\n",
    "            data[previousColumn] = (data[previousColumn] - data[column]) / 1000000 # convert into millions\n",
    "\n",
    "        previousColumn = column\n",
    "    \n",
    "    # convert the last month i.e Jan into convert into millions\n",
    "    data[data.columns[1:2]] = data[data.columns[1:2]] / 1000000\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the string\n",
    "def splitYear(row):\n",
    "    return row.Year.split()[0]\n",
    "\n",
    "# Function to calculate the growth percentage\n",
    "def CalculateGrowth(data):\n",
    "    diff = (data / data.shift(1) - 1) * 100\n",
    "    return diff\n",
    "\n",
    "# Function to fix the date data without the day\n",
    "def FixDate(data):\n",
    "    fixedData = pd.to_datetime(data, format='%b-%y', errors='ignore')\n",
    "    return fixedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read ridership data, cleanup, fix and save to sqllite db for later use\n",
    "def ReadAndFixTTCRidershipData(updateDB = False, dbConn = None):\n",
    "    # Read excel file for Analysis of TTC ridership\n",
    "    ridershipAnalysis = pd.read_excel('TTCRidership.xlsx', skiprows=5) # Skip first 5 rows with report headings    \n",
    "    \n",
    "    # Fix column names by providing the correct values to rename() function\n",
    "    ridershipAnalysis = ridershipAnalysis.rename(columns=\n",
    "                                             {\n",
    "                                                 ' 2015 *': '2015', \n",
    "                                                 'Unnamed: 0': 'Ridership', \n",
    "                                                 '  FARE MEDIA': 'FareMedia'\n",
    "                                             })\n",
    "    \n",
    "    # Delete rows starting from System Total onward using the index\n",
    "    ridershipAnalysis = ridershipAnalysis.drop(ridershipAnalysis.index[46:52])\n",
    "   \n",
    "    # Find rows with sub-total in FareMedia values\n",
    "    rowToDelete = ridershipAnalysis[ridershipAnalysis['FareMedia'].str.find('SUB-TOTAL')>0].index\n",
    "\n",
    "    # Delete all rows with sub-total values\n",
    "    ridershipAnalysis = ridershipAnalysis.drop(rowToDelete)\n",
    "\n",
    "    # Find rows with system-total in FareMedia values\n",
    "    rowToDelete = ridershipAnalysis[ridershipAnalysis['FareMedia'].str.find('SYSTEM TOTAL')>0].index\n",
    "\n",
    "    # Delete all rows with system-total values\n",
    "    ridershipAnalysis = ridershipAnalysis.drop(rowToDelete)    \n",
    "    \n",
    "    # Fix the ridership column values using forward fill method\n",
    "    ridershipAnalysis['Ridership'] = ridershipAnalysis['Ridership'].ffill()\n",
    "    \n",
    "    # Find rows with the following categories values in FareMedia columns and\n",
    "    # create a new attribute 'Passenger' of passenger types\n",
    "    categoryList = ['ADULT', 'SENIOR/STUDENT', 'CHILDREN', 'OTHERS', 'BUS', 'RAIL', 'WEEKDAY', 'WEEKEND/HOLIDAY']\n",
    "    ridershipAnalysis['Passenger'] = ridershipAnalysis[ridershipAnalysis.FareMedia.isin(categoryList)].FareMedia\n",
    "\n",
    "    # Fix others category data\n",
    "    categoryOther = 'DAY/VIST./OTHER'\n",
    "    rowToUpdate = ridershipAnalysis[ridershipAnalysis.FareMedia.str.find(categoryOther)>0].index\n",
    "    ridershipAnalysis.loc[rowToUpdate, 'Passenger'] = 'OTHERS'\n",
    "\n",
    "    # Fix the Passenger column NaN values using forward fill method\n",
    "    ridershipAnalysis['Passenger'] = ridershipAnalysis['Passenger'].ffill()\n",
    "\n",
    "    # Find all category rows with Nan values and delete\n",
    "    rowToDelete = ridershipAnalysis[ridershipAnalysis.FareMedia.isin(categoryList) & ridershipAnalysis['2016'].isnull()].index\n",
    "    ridershipAnalysis = ridershipAnalysis.drop(rowToDelete)\n",
    "    \n",
    "    # Fill all NaN values with 0 and convert float values to int\n",
    "    ridershipAnalysis.iloc[:,2:-1] = ridershipAnalysis.iloc[:,2:-1].fillna(0).astype(int)\n",
    "\n",
    "    # Replace trailing spaces in FareMedia values\n",
    "    ridershipAnalysis['FareMedia'] = ridershipAnalysis['FareMedia'].str.strip(' ')\n",
    "    \n",
    "    # Reset the index\n",
    "    ridershipAnalysis = ridershipAnalysis.reset_index(drop=True)\n",
    "\n",
    "    # Save to sqllite db if updateDB is True\n",
    "    if updateDB:\n",
    "        SaveDataframeInDB(ridershipAnalysis, tnRidershipAnalysis, dbConn)\n",
    "\n",
    "    return ridershipAnalysis\n",
    "\n",
    "# Function to get the ridership data\n",
    "def GetRidershipAnalysisData():\n",
    "    # Check if data is already cleaned and saved into db\n",
    "    if IsTableExists(tnRidershipAnalysis, ttcDbConn):\n",
    "        # Read ridership analysis data from db\n",
    "        result = ReadTableFromDB(tnRidershipAnalysis, ttcDbConn)\n",
    "    else :\n",
    "        # Call function to read TTC ridership source file, clean the data and save into the db\n",
    "        result = ReadAndFixTTCRidershipData(True, ttcDbConn)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read peak/non-peak ridership data, cleanup, fix and save to sqllite db for later use\n",
    "def ReadAndFixPeakNonPeakRidershipData(sourceFileName, tableName, oldColName, newColName, updateDB = False, dbConn = None):\n",
    "    # Read TTC Annual Passenger Rides Non-Peak\n",
    "    #nonPeakRiders = pd.read_csv('TTC Annual Passenger Rides Non-Peak.csv')\n",
    "    ridersData = pd.read_csv(sourceFileName)\n",
    "\n",
    "    # fix year column by splitting\n",
    "    ridersData.Year = ridersData.apply(splitYear, axis=1)\n",
    "\n",
    "    # set the index to year of ridership\n",
    "    ridersData = ridersData.set_index('Year')\n",
    "    \n",
    "    # Fix column names by providing the correct values to rename() function\n",
    "    ridersData = ridersData.rename(\n",
    "        columns= { '{ocn}'.format(ocn=oldColName) : '{ncn}'.format(ncn=newColName) }\n",
    "    )\n",
    "    \n",
    "    # create new attribute Growth by using the shifting the data\n",
    "    ridersData['Growth'] = CalculateGrowth(ridersData[newColName])\n",
    "\n",
    "    # fill the empty year\n",
    "    ridersData.fillna(0)\n",
    "\n",
    "    # sort the year in descending and get the top 5 or pass number to head() for getting x years of data\n",
    "    ridersData = ridersData.sort_index(ascending=False) # .head().sort_index()\n",
    "\n",
    "    # Save to sqllite db if updateDB is True\n",
    "    if updateDB:\n",
    "        SaveDataframeInDB(ridersData, tableName, dbConn)\n",
    "            \n",
    "    return ridersData\n",
    "\n",
    "# Function to get the ridership data\n",
    "def GetNonPeakRidersData():\n",
    "    # Check if data is already cleaned and saved into db\n",
    "    if IsTableExists(tnNonPeakRiders, ttcDbConn):\n",
    "        # Read ridership analysis data from db\n",
    "        result = ReadTableFromDB(tnNonPeakRiders, ttcDbConn)\n",
    "    else:\n",
    "        # Call function to read TTC ridership source file, clean the data and save into the db\n",
    "        result = ReadAndFixPeakNonPeakRidershipData(\n",
    "            srcFileRidesNonPeak,\n",
    "            tnNonPeakRiders, \n",
    "            colToFixRidesNonPeak, \n",
    "            newColRidesNonPeak,\n",
    "            True, \n",
    "            ttcDbConn)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Function to get the ridership data\n",
    "def GetPeakRidersData():\n",
    "    # Check if data is already cleaned and saved into db\n",
    "    if IsTableExists(tnPeakRiders, ttcDbConn):\n",
    "        # Read peak riders  data from db\n",
    "        result = ReadTableFromDB(tnPeakRiders, ttcDbConn)\n",
    "    else:\n",
    "        # Call function to read peak/non-peak riders source file, clean the data and save into the db\n",
    "        result = ReadAndFixPeakNonPeakRidershipData(\n",
    "            srcFileRidesPeak,\n",
    "            tnPeakRiders, \n",
    "            colToFixRidesPeak, \n",
    "            newColRidesPeak,\n",
    "            True, \n",
    "            ttcDbConn)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read monthly ridership data, cleanup, fix and save to sqllite db for later use\n",
    "def ReadAndFixMonthlyRidershipData(sourceFileName, tableName, columnName, updateDB = False, dbConn = None):\n",
    "    # Read TTC Monthly Passenger Rides\n",
    "    monthlyRiders = pd.read_csv(sourceFileName, parse_dates=['Year'])\n",
    "\n",
    "    # set the index to year of ridership\n",
    "    monthlyRiders = monthlyRiders.set_index('Year')\n",
    "\n",
    "    # create new attribute Growth by using the shifting the data\n",
    "    monthlyRiders['Growth'] = CalculateGrowth(monthlyRiders[columnName])\n",
    "\n",
    "    # fill the empty year\n",
    "    monthlyRiders.fillna(0)\n",
    "\n",
    "    # Find rows for 2017\n",
    "    rowToDelete = monthlyRiders[monthlyRiders.index.str.endswith('17')].index\n",
    "\n",
    "    # Delete all rows for 2017\n",
    "    monthlyRiders = monthlyRiders.drop(rowToDelete)\n",
    "    \n",
    "    # Save to sqllite db if updateDB is True\n",
    "    if updateDB:\n",
    "        SaveDataframeInDB(monthlyRiders, tableName, dbConn)\n",
    "            \n",
    "    return monthlyRiders\n",
    "\n",
    "# Function to get the ridership data\n",
    "def GetMonthlyRidersData():\n",
    "    # Check if data is already cleaned and saved into db\n",
    "    if IsTableExists(tnMonthlyRiders, ttcDbConn):\n",
    "        # Read ridership analysis data from db\n",
    "        result = ReadTableFromDB(tnMonthlyRiders, ttcDbConn)\n",
    "    else:\n",
    "        # Call function to read TTC monthly ridership source file, clean the data and save into the db\n",
    "        result = ReadAndFixMonthlyRidershipData(\n",
    "            srcFileMonthlyRiders,\n",
    "            tnMonthlyRiders,\n",
    "            colMonthlyRidership,\n",
    "            True, \n",
    "            ttcDbConn)\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read ridership revenue data, cleanup, fix and save to sqllite db for later use\n",
    "def ReadAndFixRidersRevenueData(sourceFileName, tableName, updateDB = False, dbConn = None):\n",
    "    # Read TTC Ridership Revenues data\n",
    "    ridersRevenue = pd.read_csv(sourceFileName)\n",
    "    \n",
    "    # Fix the dollar amount and convert into int, by replacing $ and ,\n",
    "    # create a list of columns and put them in a list\n",
    "    cols = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "    # pass them to replace(), specifying each char and it's replacement:\n",
    "    ridersRevenue[cols] = ridersRevenue[cols].replace({'\\$': '', ',': ''}, regex=True)\n",
    "\n",
    "    # fill NaN value\n",
    "    ridersRevenue[cols] = ridersRevenue[cols].fillna(0)\n",
    "\n",
    "    # Convert data to integer\n",
    "    ridersRevenue[cols] = ridersRevenue[cols].astype(int)\n",
    "\n",
    "    # fix year column by splitting and set the index\n",
    "    ridersRevenue = ridersRevenue.set_index(ridersRevenue.apply(splitYear, axis=1))\n",
    "\n",
    "    # Call function to update data\n",
    "    FixAccumulatedMonthValues(ridersRevenue)\n",
    "\n",
    "    ridersRevenue = ridersRevenue[ridersRevenue.index != '2017']\n",
    "    \n",
    "    # Save to sqllite db if updateDB is True\n",
    "    if updateDB:\n",
    "        SaveDataframeInDB(ridersRevenue, tableName, dbConn)\n",
    "            \n",
    "    return ridersRevenue\n",
    "\n",
    "# Function to get the ridership data\n",
    "def GetRidersRevenueData():\n",
    "    # Check if data is already cleaned and saved into db\n",
    "    if IsTableExists(tnRidershipRevenues, ttcDbConn):\n",
    "        # Read ridership analysis data from db\n",
    "        result = ReadTableFromDB(tnRidershipRevenues, ttcDbConn)\n",
    "    else:\n",
    "        # Call function to read TTC ridership revenue source file, clean the data and save into the db\n",
    "        result = ReadAndFixRidersRevenueData(\n",
    "            srcFileRidershipRevenues,\n",
    "            tnRidershipRevenues,\n",
    "            True, \n",
    "            ttcDbConn)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph related function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the graph\n",
    "def SaveGraph(title, fig):\n",
    "    # Cleans the title to use as filename for graph to save\n",
    "    fileName = title.replace(\"/\", \" \").replace(\" \", \"\")\n",
    "    # Save the graph as png file, used bbox_inches='tight' to fit the whole chart when saving\n",
    "    fig.savefig(\"{fn}.png\".format(fn=fileName), dpi=fig.dpi, bbox_inches='tight')\n",
    "   \n",
    "    \n",
    "# Function to set explode value for pie slice\n",
    "def isExplode(x):\n",
    "    if x['Explode'] == True:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Function to draw pie chart and explode the slice with max size\n",
    "def DrawPieChart(data, title, excludeLessThan = True, legend = ''):\n",
    "    # Calculate the pie size and create new attribute\n",
    "    data['Size'] = data / data.sum() * 100\n",
    "\n",
    "    # Create new attribute to set the explode slice\n",
    "    data['Explode'] = data['Size'].max() == data['Size']    \n",
    "    data['Explode'] = data.apply(isExplode, axis=1)\n",
    "                                       \n",
    "    # Exclude slice values less than 1%\n",
    "    if excludeLessThan == True:\n",
    "        data = data[data['Size']>1]\n",
    "    else:\n",
    "        data = data[data['Size']>0]\n",
    "\n",
    "    # Set the label, slice percent and size to explode\n",
    "    labels = data.index\n",
    "    sizes = data['Size']\n",
    "    explode = data['Explode']  # only \"explode\" the slice with max size\n",
    "\n",
    "    if legend == '':\n",
    "        legend = labels\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(15,8))\n",
    "    ax.pie(sizes, explode=explode, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.legend(legend, loc=\"upper right\")\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(data)\n",
    "    \n",
    "    # Call function to save the graph as png file\n",
    "    SaveGraph(title, fig)\n",
    "    \n",
    "\n",
    "# Function to plot a chart of type kind, default is line\n",
    "def DrawChart(data, title, yLabel, kind='line'):\n",
    "    \n",
    "    # Define subplots to draw line chart and the summary of the data we have\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    data.plot(kind=kind, ax=ax, figsize=(15,8))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize=20)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.show()\n",
    "    print(data)\n",
    "\n",
    "    # Call function to save the graph as png file\n",
    "    SaveGraph(title, fig)\n",
    "    \n",
    "def DrawRidershipTrend(data):\n",
    "    # Get total ridership from all years \n",
    "    totalRidership =pd.DataFrame({'Total Ridership': data[['WEEKDAY','WEEKEND/HOLIDAY']].transpose().sum()/1000})\n",
    "\n",
    "    # Define subplots to draw line chart and the summary of the data we have\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Draw the table describing the data we have for ridership\n",
    "    table(ax, np.round(totalRidership.describe(), 2), loc='lower right', colWidths=[0.2, 0.2, 0.2]) \n",
    "\n",
    "    # Format title for the plot using min and max for index\n",
    "    title = \"Ridership Trend From {sy} To {ey}\".format(sy=totalRidership.index.min(), ey=totalRidership.index.max())\n",
    "\n",
    "    # Plot line chart for the ridership\n",
    "    totalRidership.plot(title=title, ax=ax, legend=None, figsize=(15,4), linestyle='-', marker='o' )\n",
    "    plt.ylabel(\"Total Ridership in Millions\")\n",
    "    # Hack to draw all year in the graph :)\n",
    "    bar = totalRidership/1000\n",
    "    bar.plot(kind='bar', ax=ax)\n",
    "\n",
    "    # Call function to save the graph as png file\n",
    "    SaveGraph(title, fig)\n",
    "    \n",
    "    return totalRidership\n",
    "\n",
    "# Function to set the label of subplots\n",
    "def label(ax, string):\n",
    "    ax.annotate(string, (1, 1), xytext=(-8, -4), ha='right', va='top', size=14, \n",
    "                xycoords='axes fraction', textcoords='offset points')    \n",
    "\n",
    "# Function to draw the autocorrelation graph\n",
    "def DrawAutoCorrelation(data, title):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, figsize=(12, 12))\n",
    "    \n",
    "    # using tight layout so there is no space between title and sub plots\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # set the title for graph\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    label(axes[0], 'Trend')\n",
    "    axes[0].plot(data)    \n",
    "    \n",
    "    lags, c, line, b = axes[1].acorr(data, maxlags=data.size-1)\n",
    "    label(axes[1], 'Matplotlib Autocorrelation %.2f' % np.mean(c))\n",
    "    \n",
    "    label(axes[2], 'Pandas Autocorrelation')\n",
    "    pd.plotting.autocorrelation_plot(data, ax=axes[2])    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process ridership data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call function to get the ridership data either from db or source file\n",
    "ridershipAnalysis = GetRidershipAnalysisData()\n",
    "\n",
    "# Sort the data by columns\n",
    "ridershipAnalysisSorted = ridershipAnalysis[ridershipAnalysis.columns.sort_values()]\n",
    "\n",
    "# Groups the data by Passenger and Fare Type and also transpose\n",
    "fixedRidershipData = ridershipAnalysisSorted.groupby(['Passenger', 'FareMedia']).mean().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Ridership Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to draw total ridership graph\n",
    "totalRidership = DrawRidershipTrend(fixedRidershipData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridership proportion by passenger type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Adult media type for 2016\n",
    "fareMediaForAdult = fixedRidershipData['ADULT'].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForAdult, 'Ridership of Adult Passengers in 2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Children media type for 2016\n",
    "fareMediaForChildren = fixedRidershipData['CHILDREN'].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForChildren, 'Ridership of Children Passengers in 2016', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Senior/Student media type for 2016\n",
    "fareMediaForSeniorStudent = fixedRidershipData['SENIOR/STUDENT'].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForSeniorStudent, 'Ridership of Senior/Student Passengers in 2016', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Senior/Student media type for 2016\n",
    "fareMediaForSeniorStudent = fixedRidershipData['RAIL'].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForSeniorStudent, 'Ridership of Rail Passengers in 2016', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Other media type for 2016\n",
    "fareMediaForSeniorStudent = fixedRidershipData['OTHERS'].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForSeniorStudent, 'Ridership of Others Passengers in 2016', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pie chart for Other media type for 2016\n",
    "fareMediaForSeniorStudent = fixedRidershipData[['WEEKDAY', 'WEEKEND/HOLIDAY']].tail(1).transpose()\n",
    "DrawPieChart(fareMediaForSeniorStudent, 'Weekly Ridership in 2016', False, ['WEEKDAY', 'WEEKEND/HOLIDAY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly Ridership by Bus and Rail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw line chart for BUS and RAIL media type\n",
    "# This should include all modes of transport\n",
    "DrawChart(fixedRidershipData[['BUS','RAIL']].tail()/1000, \"Bus/Rail ridership\", \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly Ridership by Media Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(fixedRidershipData['ADULT'].tail()/1000, \"ADULT ridership\", \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(fixedRidershipData['CHILDREN'].tail()/1000, \"CHILDREN ridership\", \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(fixedRidershipData['SENIOR/STUDENT'].tail()/1000, \"SENIOR/STUDENT ridership\", \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(fixedRidershipData[['WEEKDAY','WEEKEND/HOLIDAY']]/1000, \"Weekday vs Weekend Ridership\", \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly weekday and weekend ridership ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fixedRidershipData['Ratio'] = fixedRidershipData['WEEKDAY']['WEEKDAY'] / fixedRidershipData['WEEKEND/HOLIDAY']['WEEKEND/HOLIDAY']\n",
    "DrawChart(fixedRidershipData[['Ratio']], \"Ratio of Weekday to Weekend Ridership\", \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by Passenger  and sum the value\n",
    "ridershipDataForCorr = ridershipAnalysisSorted.groupby(['Passenger']).sum().transpose()\n",
    "\n",
    "# We get the following groups\n",
    "# ADULT, SENIOR/STUDENT, CHILDREN, OTHERS, WEEKDAY, WEEKEND/HOLIDAY, BUS, RAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for Adult ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['ADULT']/1000, 'Adults Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for SENIOR/STUDENT ridership\n",
    "DrawAutoCorrelation(ridershipDataForCorr['SENIOR/STUDENT']/1000, 'Senior/Student Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for CHILDREN ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['CHILDREN']/1000, 'Children Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for OTHERS ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['OTHERS']/1000, 'Others Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for WEEKDAY ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['WEEKDAY']/1000, 'Weekday Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for WEEKEND/HOLIDAY ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['WEEKEND/HOLIDAY']/1000, 'Weekend/Holiday Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for BUS ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['BUS']/1000, 'Bus Ridership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph for Rail ridership also convert the values into thousands\n",
    "DrawAutoCorrelation(ridershipDataForCorr['RAIL']/1000, 'Rail Ridership')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Annual Peak and Non-Peak Ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process non peak ridership data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to get the non peak ridership data either from db or source file\n",
    "nonPeakRiders = GetNonPeakRidersData()\n",
    "\n",
    "# get the top 5 or pass number to head() for getting x years of data\n",
    "topNonPeakRiders = nonPeakRiders.head().sort_index()\n",
    "\n",
    "DrawChart(topNonPeakRiders.Growth, \"Annual Ridership Non-Peak\", \"Ridership Growth Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process peak ridership data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to get the non peak ridership data either from db or source file\n",
    "peakRiders = GetPeakRidersData()\n",
    "\n",
    "# get the top 5 or pass number to head() for getting x years of data\n",
    "topPeakRiders = peakRiders.head().sort_index()\n",
    "\n",
    "DrawChart(topPeakRiders.Growth, \"Annual Passenger Rides Peak\", \"Ridership Growth Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Peak and Non-Peak Ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat peak and non peak riders data frame\n",
    "peakNopeak = pd.concat([topPeakRiders, topNonPeakRiders], axis =1)\n",
    "peakNopeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Growth column names\n",
    "peakNopeak.columns.values[1] = \"Peak Growth\"\n",
    "peakNopeak.columns.values[3] = \"Non-Peak Growth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw chart for \n",
    "DrawChart(peakNopeak[['Peak Growth', 'Non-Peak Growth']], \n",
    "          \"Annual Riders Growth Peak & Non-Peak\", \n",
    "          \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(peakNopeak[[newColRidesPeak, newColRidesNonPeak]]/1000, \n",
    "          \"Annual Riders Peak & Non-Peak\", \n",
    "          \"Ridership in Millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Passenger Ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read monthly riders data\n",
    "monthlyRiders = GetMonthlyRidersData()\n",
    "\n",
    "# Get the last 5 months or pass number to tail() for getting x months of data\n",
    "topMonthlyRiders = monthlyRiders.tail(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(topMonthlyRiders.Growth, \"Monthly Passenger Rides Peak\", \"Ridership Growth Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridership Revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read riders revenue data excluding 2017\n",
    "ridersRevenueWOTarget = GetRidersRevenueData()\n",
    "ridersRevenueWOTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(ridersRevenueWOTarget[ridersRevenueWOTarget.columns[2:]].tail(), \n",
    "          \"Monthly Revenue\", \"Amount in millions\", 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = ridersRevenueWOTarget[ridersRevenueWOTarget.columns[1:]].transpose()\n",
    "monthly[monthly.columns[5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawChart(monthly[monthly.columns[5:]], \n",
    "          \"Monthly Revenue comparison with previous years\", \"Amount in millions\", 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for Ridership and Revenue trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data for linear regression\n",
    "# Sum the transpose ridership and revenue data by year\n",
    "revenue = ridersRevenueWOTarget[ridersRevenueWOTarget.columns[1:]].transpose().sum()\n",
    "ridership = fixedRidershipData[['WEEKDAY','WEEKEND/HOLIDAY']].tail(10).transpose().sum()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for regression test\n",
    "data = {'Revenue': revenue / 100, 'Ridership': ridership / 100}\n",
    "ridershipRevenueData = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to use with statsmodels OLS model\n",
    "X = ridershipRevenueData['Ridership']\n",
    "y = ridershipRevenueData['Revenue']\n",
    "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to use with sklearn linear regression\n",
    "lr = LinearRegression()\n",
    "data = np.matrix( ridershipRevenueData )\n",
    "X, Y = data[:,1], data[:,0]\n",
    "lr.fit(X, Y)\n",
    "score = '{0:.3f}'.format( lr.score(X, Y) )\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw scatter graph and plot predicted test data - alpha=0.5, \n",
    "fig, axScatter = plt.subplots(figsize=(15, 8))\n",
    "axScatter.scatter(ridershipRevenueData.Ridership, ridershipRevenueData.Revenue, \n",
    "                  marker='o', edgecolor='b', facecolor='b', alpha=0.4, s=80, label='Ridership and Revenue')\n",
    "\n",
    "test = np.arange( 3.75, 5.75, 0.1 )\n",
    "test = np.array( np.matrix( test ).T )\n",
    "plt.plot( test, lr.predict( test ), 'g--')\n",
    "\n",
    "plt.xlabel('Ridership')\n",
    "plt.ylabel('Revenue')\n",
    "plt.axis([4.5, 5.5,7.0,12.0])\n",
    "plt.title('Regression of Revenue from Ridership') ;\n",
    "plt.grid() ;\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('Ridership_v_Revenue.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Using statsmodels ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive integrated moving average\n",
    "# The ARIMA model can be used to forecast future time steps\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "series = totalRidership['Total Ridership']\n",
    "X = series.values\n",
    "\n",
    "# Calculate the size for breaking the ridership data into model and test data\n",
    "size = int(len(X) * 0.9)\n",
    "\n",
    "# breaking data in to model and test data\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# declare a variable to hold the training model data\n",
    "history = [x for x in train]\n",
    "\n",
    "# variable to keep the predicted data\n",
    "predictions = list()\n",
    "\n",
    "# loop through test data and predict the trend\n",
    "for t in range(len(test)):\n",
    "    \n",
    "    # Fit an ARIMA(5,1,0) model. \n",
    "    # This sets the lag value to 5 for autoregression, \n",
    "    # uses a difference order of 1 to make the time series stationary, \n",
    "    # and uses a moving average model of 0.    \n",
    "    model = ARIMA(history, order=(5,1,0)) \n",
    "    model_fit = model.fit(disp=0)\n",
    "    \n",
    "    # get the output of forcast()\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    \n",
    "    # add to prediction list\n",
    "    predictions.append(yhat)\n",
    "    \n",
    "    # add test data into history list\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    \n",
    "    # print predicated and expected value\n",
    "    #print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    \n",
    "# Calculate a final mean squared error score (MSE) for the predictions, \n",
    "# providing a point of comparison for other ARIMA configurations.\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "\n",
    "# Prepare data to plot chart\n",
    "predicted = [x[0] for x in predictions]\n",
    "data = {'Expected': test, 'Predicted': predicted}\n",
    "predictionData = pd.DataFrame(data)\n",
    "\n",
    "#Create subplot to plot line chart\n",
    "fig, axScatter = plt.subplots(figsize=(15, 8))\n",
    "axScatter.plot(test, 'g-', label='Expected')\n",
    "axScatter.plot(predicted, 'r--', label='Predicted')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Ridership')\n",
    "plt.title('Autoregressive integrated moving average of Ridership', fontsize=20) ;\n",
    "plt.grid() ;\n",
    "plt.legend(loc='upper left', fontsize=20)\n",
    "plt.savefig('ARIMARidership.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
